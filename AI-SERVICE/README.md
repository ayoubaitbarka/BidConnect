# AI-SERVICE (RAG)

Service d'Intelligence Artificielle bas√© sur RAG (Retrieval Augmented Generation) pour la plateforme BidConnect.

## üéØ Fonctionnalit√©s

- **Ingestion de documents** : Chargement, d√©coupage et indexation de documents
- **Embeddings vectoriels** : G√©n√©ration d'embeddings via OpenAI
- **Base vectorielle** : Stockage dans Qdrant pour recherche s√©mantique
- **Chat RAG** : Chatbot contextuel bas√© sur les documents ing√©r√©s
- **API REST** : Endpoints document√©s via Swagger

## üèóÔ∏è Architecture

### Stack Technique
- **Java 21** + **Spring Boot 3.3.6**
- **LangChain4j 0.34.0** : Framework RAG
- **Qdrant** : Base vectorielle (Docker)
- **PostgreSQL** : M√©tadonn√©es (Docker)
- **OpenAI** : LLM et embeddings

### Structure
```
src/main/java/com/example/aiservice/
‚îú‚îÄ‚îÄ config/          # Configuration LangChain4j
‚îú‚îÄ‚îÄ controller/      # REST API
‚îú‚îÄ‚îÄ dto/             # Request/Response objects
‚îú‚îÄ‚îÄ entity/          # JPA entities
‚îú‚îÄ‚îÄ repository/      # Data access
‚îî‚îÄ‚îÄ service/         # Business logic
```

## üöÄ D√©marrage

### Pr√©requis
- Java 21
- Docker & Docker Compose
- Cl√© API OpenAI

### 1. D√©marrer l'infrastructure

```bash
docker-compose up -d
```

Cela d√©marre :
- **Qdrant** sur le port `6333`
- **PostgreSQL** sur le port `5433`

### 2. Configurer la cl√© OpenAI

```bash
export OPENAI_API_KEY="votre-cl√©-api"
```

Ou modifier `application.yml` :
```yaml
langchain4j:
  open-ai:
    chat-model:
      api-key: "votre-cl√©-api"
```

### 3. Compiler et lancer

```bash
./mvnw clean package
java -jar target/AI-SERVICE-0.0.1-SNAPSHOT.jar
```

Le service d√©marre sur **http://localhost:8085**

## üìö Documentation API (Swagger)

Acc√©der √† : **http://localhost:8085/swagger-ui.html**

### Endpoints principaux

#### 1. Ingestion de document
```http
POST /api/ai/ingest
Content-Type: application/json

{
  "documentId": "doc-123",
  "documentUrl": "http://localhost:8081/api/documents/doc-123/download"
}
```

**R√©ponse :**
```json
{
  "documentId": "doc-123",
  "status": "COMPLETED",
  "chunkCount": 42,
  "message": "Document successfully ingested"
}
```

#### 2. Chat RAG
```http
POST /api/ai/chat
Content-Type: application/json

{
  "query": "Quelles sont les conditions de l'appel d'offres ?",
  "conversationId": null
}
```

**R√©ponse :**
```json
{
  "answer": "Les conditions sont...",
  "sources": [],
  "conversationId": "uuid-123"
}
```

## üîÑ Flux RAG

### Ingestion
1. T√©l√©chargement du document depuis `document-service`
2. D√©coupage en chunks (500 caract√®res, overlap 50)
3. G√©n√©ration d'embeddings (OpenAI `text-embedding-3-small`)
4. Stockage dans Qdrant
5. Sauvegarde m√©tadonn√©es dans PostgreSQL

### Chat
1. R√©ception de la question utilisateur
2. G√©n√©ration embedding de la question
3. Recherche des 5 chunks les plus similaires (score > 0.7)
4. Construction du contexte
5. G√©n√©ration de la r√©ponse via GPT-3.5-turbo
6. Retour de la r√©ponse + sources

## üß™ Tests

### Test d'ingestion
```bash
curl -X POST http://localhost:8085/api/ai/ingest \
  -H "Content-Type: application/json" \
  -d '{
    "documentId": "test-doc",
    "documentUrl": "https://example.com/document.pdf"
  }'
```

### Test de chat
```bash
curl -X POST http://localhost:8085/api/ai/chat \
  -H "Content-Type: application/json" \
  -d '{
    "query": "R√©sume le document",
    "conversationId": null
  }'
```

## üê≥ Docker

### Build de l'image
```bash
./mvnw clean package
docker build -t ai-service:latest .
```

### Lancement complet
```bash
docker-compose up -d
docker run -p 8085:8085 \
  -e OPENAI_API_KEY=your-key \
  --network host \
  ai-service:latest
```

## üîß Configuration

### Variables d'environnement
- `OPENAI_API_KEY` : Cl√© API OpenAI (obligatoire)
- `SPRING_DATASOURCE_URL` : URL PostgreSQL (d√©faut: `jdbc:postgresql://localhost:5433/ai_db`)
- `LANGCHAIN4J_QDRANT_HOST` : H√¥te Qdrant (d√©faut: `localhost`)

### Param√®tres RAG
Dans `application.yml` :
```yaml
langchain4j:
  qdrant:
    collection-name: bid_embeddings  # Nom de la collection
```

## üìä Monitoring

### V√©rifier Qdrant
```bash
curl http://localhost:6333/collections/bid_embeddings
```

### V√©rifier PostgreSQL
```bash
docker exec -it ai-db psql -U ai_user -d ai_db
SELECT * FROM document_metadata;
```

## üîó Int√©gration avec les autres services

### Avec SOUMISSION-SERVICE
Le service peut √™tre appel√© apr√®s la soumission d'un dossier pour analyser la conformit√©.

### Avec DOCUMENT-SERVICE
R√©cup√®re les documents via l'URL de t√©l√©chargement.

## ‚ö†Ô∏è Limitations actuelles

- Pas d'authentification (√† ajouter)
- Extraction des sources non impl√©ment√©e
- D√©tection automatique du type MIME manquante
- Pas de gestion de la m√©moire de conversation persistante

## üìù TODO

- [ ] Ajouter s√©curit√© (JWT)
- [ ] Impl√©menter extraction des sources
- [ ] Support multi-langues
- [ ] Cache des embeddings
- [ ] M√©triques Prometheus

## üë• Auteur

D√©velopp√© pour le projet BidConnect
